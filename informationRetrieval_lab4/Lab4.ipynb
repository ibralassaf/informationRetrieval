{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 1: Demonstrate how can you apply the Porter \r\n",
    "Stemmer for finding the stem of word “Understanding” and \r\n",
    "“Demonstration”! "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "نكتب الخطوات يدويًا من الرابط"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 2: Assume you have a list of words that you want \r\n",
    "to get their stem, write python script that find stem of \r\n",
    "each word in the list. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import nltk \r\n",
    "from nltk.stem import PorterStemmer\r\n",
    "nltk.download('punkt')\r\n",
    "porter = PorterStemmer()\r\n",
    "#l_words = ['dogs','programming','programs','programmed','cakes','indices','matrices']\r\n",
    "#for word in l_words:\r\n",
    "#    print(f'{word} \\t -> {porter.stem(word)}'.expandtabs(15))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ibrahim\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dogs            -> dog\n",
      "programming     -> program\n",
      "programs        -> program\n",
      "programmed      -> program\n",
      "cakes           -> cake\n",
      "indices         -> indic\n",
      "matrices        -> matric\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print(porter.stem(\"Understanding\"))\r\n",
    "print(porter.stem(\"Demonstrantion\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "understand\n",
      "demonstrant\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 3: Now, apply Poster Stemmer on the following \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "from nltk.tokenize import word_tokenize\r\n",
    "\r\n",
    "text = nltk.word_tokenize('A stemmer for English operating on the stem cat should identify such strings as cats, catlike, and catty. A stemming algorithm might also reduce the words fishing, fished, and fisher to the stem fish. The stem need not be a word, for example the Porter algorithm reduces, argue, argued, argues, arguing, and argus to the stem argu.') \r\n",
    "processedText = []\r\n",
    "for item in text:\r\n",
    "  stem = porter.stem(item)\r\n",
    "  processedText.append(stem)\r\n",
    "\r\n",
    "processedText = \" \".join(processedText)\r\n",
    "print(processedText)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "a stemmer for english oper on the stem cat should identifi such string as cat , catlik , and catti . a stem algorithm might also reduc the word fish , fish , and fisher to the stem fish . the stem need not be a word , for exampl the porter algorithm reduc , argu , argu , argu , argu , and argu to the stem argu .\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 3: Repeat the task presented in exercise 2. Then, \r\n",
    "compare outputs! Do you find a difference between Porter \r\n",
    "Stemmer outputs and Lancaster Stemmer? Why??? "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "import nltk \r\n",
    "from nltk.stem import LancasterStemmer\r\n",
    "lancaster = LancasterStemmer()\r\n",
    "l_words = ['dogs','programming','programs','programmed','cakes','indices','matrices']\r\n",
    "for word in l_words:\r\n",
    "    print(f'{word} \\t -> {lancaster.stem(word)}'.expandtabs(15))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dogs            -> dog\n",
      "programming     -> program\n",
      "programs        -> program\n",
      "programmed      -> program\n",
      "cakes           -> cak\n",
      "indices         -> ind\n",
      "matrices        -> mat\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercise 4: Check how to perform stemming using \r\n",
    "SnowballStemmer and Write your python script below! "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "import nltk \r\n",
    "from nltk.stem import SnowballStemmer\r\n",
    "print(\" \".join(SnowballStemmer.languages))\r\n",
    "stemmer = SnowballStemmer(\"arabic\")\r\n",
    "stemmer.stem(\"حركات\") "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "arabic danish dutch english finnish french german hungarian italian norwegian porter portuguese romanian russian spanish swedish\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'حرك'"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "from nltk.stem.isri import ISRIStemmer \r\n",
    "st = ISRIStemmer() \r\n",
    "w = 'حركات' \r\n",
    "print(st.stem(w)) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "حرك\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stemming a document \r\n",
    "You can write your own function that can stem documents. Here is one way to stem a \r\n",
    "document using Python filing: \r\n",
    "<ol>\r\n",
    "<li>\r\n",
    "Take a document as the input. \r\n",
    "</li>\r\n",
    "<li>\r\n",
    "Read the document line by line \r\n",
    "</li>\r\n",
    "<li>\r\n",
    "Tokenize the line \r\n",
    "</li>\r\n",
    "<li>\r\n",
    "Stem the words \r\n",
    "</li>\r\n",
    "<li>\r\n",
    "Output the stemmed words (print on screen or write to a file) \r\n",
    "</li>\r\n",
    "<li>\r\n",
    "Repeat step 2 to step 5 until it is to the end of the document. \r\n",
    "</li>\r\n",
    "</or>\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "file=open(\"data-science-wiki.txt\") \r\n",
    "Sentences= file.read() \r\n",
    "def stemSentence(sentence): \r\n",
    "    token_words=word_tokenize(sentence) \r\n",
    "    token_words \r\n",
    "    stem_sentence=[] \r\n",
    "    for word in token_words:\r\n",
    "        stem_sentence.append(porter.stem(word)) \r\n",
    "        stem_sentence.append(\" \") \r\n",
    "        return \"\".join(stem_sentence) \r\n",
    "print(Sentences) \r\n",
    "print(\"Stemmed sentence\") \r\n",
    "x=stemSentence(Sentences) \r\n",
    "print(x)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A stemmer for English operating on the stem cat sh\n",
      "ould identify such strings as cats, catlike, and catty. A stem\n",
      "ming algorithm might also reduce the words fishing, fished, an\n",
      "d fisher to the stem fish. The stem need not be a word, for ex\n",
      "ample the Porter algorithm reduces, argue, argued, argues, arg\n",
      "uing, and argus to the stem argu.\n",
      "Stemmed sentence\n",
      "a \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "53b614374e0b42b979a587b50c1889e693f4da8cea65821628dc2c85a5d09888"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}